{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9qwgdnNM_xb"
   },
   "source": [
    "### Central Limit Theorem   \n",
    "\n",
    "Answer all **Questions**\n",
    "\n",
    "References:  \n",
    "- Wikipedia, https://en.wikipedia.org/wiki/Computational_statistics  \n",
    "- Raju Varshney, https://www.geeksforgeeks.org/permutation-and-combination-in-python/    \n",
    "- Wikipedia, https://en.wikipedia.org/wiki/Central_limit_theorem    \n",
    "- Outlier AI, https://towardsdatascience.com/how-to-think-about-combinatorics-like-a-data-scientist-bddbd18eff80     \n",
    "- Computational Statistics in Python, Duke University,  \n",
    "https://people.duke.edu/~ccc14/sta-663/ResamplingAndMonteCarloSimulations.html  \n",
    "- What is a Confidence Interval?\n",
    "Source: https://stattrek.com/estimation/confidence-interval.aspx \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdXEpj1xM_xd"
   },
   "source": [
    "### Sampling with and without replacement    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFPut71zM_xe"
   },
   "source": [
    "`np.random.choice(a, size=None, replace=True, p=None)`\n",
    "\n",
    "Generates a random sample from a given 1-D array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rceh__AtM_xf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "?np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEiaBwsuM_xj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 3, 0, 1, 3, 0, 3, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling is done with replacement by default\n",
    "np.random.choice(4, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kwul5MTFM_xn",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 0, 0, 3, 0, 3, 0, 0, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability weights can be given\n",
    "np.random.choice(4, 12, p=[.4, .1, .1, .4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1kHUAwoM_xs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8],\n",
       "       [1, 3, 4, 7, 7, 3, 5, 9, 7, 9, 0, 2],\n",
       "       [3, 0, 6, 9, 5, 5, 4, 0, 3, 6, 8, 8],\n",
       "       [9, 4, 1, 9, 4, 8, 0, 2, 2, 2, 0, 5],\n",
       "       [6, 1, 8, 8, 0, 1, 2, 7, 4, 9, 5, 4],\n",
       "       [2, 5, 5, 5, 1, 2, 5, 0, 5, 3, 3, 7],\n",
       "       [9, 0, 4, 2, 9, 8, 7, 9, 6, 9, 3, 5],\n",
       "       [2, 3, 4, 8, 6, 5, 3, 0, 0, 7, 8, 2]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(0, 10, (8, 12))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atiq5HTrM_xu"
   },
   "source": [
    "`np.ravel(a, order='C')`\n",
    "\n",
    "Returns a contiguous flattened array.\n",
    "\n",
    "A 1-D array, containing the elements of the input, is returned.  A copy is\n",
    "made only if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaiTLWMZM_xv"
   },
   "outputs": [],
   "source": [
    "np.ravel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVExaXx6M_xy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 2, 6, 3, 7, 6, 8, 5, 4, 5, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling individual elements\n",
    "np.random.choice(np.ravel(x), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iug9WZ2PM_x1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 1, 8, 8, 0, 1, 2, 7, 4, 9, 5, 4],\n",
       "       [6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8],\n",
       "       [1, 3, 4, 7, 7, 3, 5, 9, 7, 9, 0, 2],\n",
       "       [6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling rows\n",
    "print(x.shape)\n",
    "idx = np.random.choice(x.shape[0], 4) # sample 4 of 8 choices/rows randomly\n",
    "x[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PQI9kimM_x5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12)\n",
      "[[6 2 9 0 1 1 6 7 1 7 5 8]\n",
      " [1 3 4 7 7 3 5 9 7 9 0 2]\n",
      " [3 0 6 9 5 5 4 0 3 6 8 8]\n",
      " [9 4 1 9 4 8 0 2 2 2 0 5]\n",
      " [6 1 8 8 0 1 2 7 4 9 5 4]\n",
      " [2 5 5 5 1 2 5 0 5 3 3 7]\n",
      " [9 0 4 2 9 8 7 9 6 9 3 5]\n",
      " [2 3 4 8 6 5 3 0 0 7 8 2]]\n",
      "[5 2 3 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 9, 0, 1],\n",
       "       [3, 4, 7, 3],\n",
       "       [5, 6, 9, 5],\n",
       "       [8, 1, 9, 8],\n",
       "       [1, 8, 8, 1],\n",
       "       [2, 5, 5, 2],\n",
       "       [8, 4, 2, 8],\n",
       "       [5, 4, 8, 5]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling columns\n",
    "print(x.shape)\n",
    "print(x)\n",
    "idx = np.random.choice(x.shape[1], 4)\n",
    "print(idx)\n",
    "x[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eVZ3QfvM_x8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot take a larger sample than population when 'replace=False'\n"
     ]
    }
   ],
   "source": [
    "# Give the argument replace=False\n",
    "\n",
    "# Note: this will throw an error. Cannot take a larger sample than population when 'replace=False'\n",
    "try:\n",
    "    print(np.random.choice(4, 12, replace=False))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugdLLG0CM_yA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8],\n",
       "       [1, 3, 4, 7, 7, 3, 5, 9, 7, 9, 0, 2],\n",
       "       [3, 0, 6, 9, 5, 5, 4, 0, 3, 6, 8, 8],\n",
       "       [9, 4, 1, 9, 4, 8, 0, 2, 2, 2, 0, 5],\n",
       "       [6, 1, 8, 8, 0, 1, 2, 7, 4, 9, 5, 4],\n",
       "       [2, 5, 5, 5, 1, 2, 5, 0, 5, 3, 3, 7],\n",
       "       [9, 0, 4, 2, 9, 8, 7, 9, 6, 9, 3, 5],\n",
       "       [2, 3, 4, 8, 6, 5, 3, 0, 0, 7, 8, 2]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRibirwgM_yC"
   },
   "source": [
    "`np.random.shuffle()` or `np.random.permutation()` can be used to generate a random permutation.\n",
    "\n",
    "`np.random.shuffle()` occurs in place. `np.random.permutation()` does the same thing but returns a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FB5kypd_M_yD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 4, 7, 7, 3, 5, 9, 7, 9, 0, 2],\n",
       "       [6, 1, 8, 8, 0, 1, 2, 7, 4, 9, 5, 4],\n",
       "       [9, 4, 1, 9, 4, 8, 0, 2, 2, 2, 0, 5],\n",
       "       [9, 0, 4, 2, 9, 8, 7, 9, 6, 9, 3, 5],\n",
       "       [6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8],\n",
       "       [2, 3, 4, 8, 6, 5, 3, 0, 0, 7, 8, 2],\n",
       "       [2, 5, 5, 5, 1, 2, 5, 0, 5, 3, 3, 7],\n",
       "       [3, 0, 6, 9, 5, 5, 4, 0, 3, 6, 8, 8]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling occurs \"in place\" for efficiency\n",
    "np.random.shuffle(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfsaNd6qM_yG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 5, 5, 1, 2, 5, 0, 5, 3, 3, 7],\n",
       "       [9, 4, 1, 9, 4, 8, 0, 2, 2, 2, 0, 5],\n",
       "       [2, 3, 4, 8, 6, 5, 3, 0, 0, 7, 8, 2],\n",
       "       [6, 1, 8, 8, 0, 1, 2, 7, 4, 9, 5, 4],\n",
       "       [3, 0, 6, 9, 5, 5, 4, 0, 3, 6, 8, 8],\n",
       "       [6, 2, 9, 0, 1, 1, 6, 7, 1, 7, 5, 8],\n",
       "       [1, 3, 4, 7, 7, 3, 5, 9, 7, 9, 0, 2],\n",
       "       [9, 0, 4, 2, 9, 8, 7, 9, 6, 9, 3, 5]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy.random.permutation does the same thing but returns a copy\n",
    "np.random.permutation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMRspyc3M_yK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 9, 1, 5, 0, 6, 8, 4, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When given an integre n, permutation treats it is as the array arange(n)\n",
    "np.random.permutation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMqNlWqEM_yN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]] \n",
      "\n",
      "[[13 14 15]\n",
      " [16 17 18]\n",
      " [19 20 21]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Use indices if you need to shuffle collections of arrays in synchrony\n",
    "x = np.arange(12).reshape(4,3)\n",
    "y = x + 10\n",
    "idx = np.random.permutation(x.shape[0])\n",
    "print(x[idx, :], '\\n')\n",
    "print(y[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjYpTDJ1M_yQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 7 7 3 5 9 7 9 0 2]\n",
      " [6 1 8 8 0 1 2 7 4 9 5 4]\n",
      " [9 4 1 9 4 8 0 2 2 2 0 5]\n",
      " [9 0 4 2 9 8 7 9 6 9 3 5]\n",
      " [6 2 9 0 1 1 6 7 1 7 5 8]\n",
      " [2 3 4 8 6 5 3 0 0 7 8 2]\n",
      " [2 5 5 5 1 2 5 0 5 3 3 7]\n",
      " [3 0 6 9 5 5 4 0 3 6 8 8]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: '%.3f' % x})\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlTps3xqM_yS"
   },
   "source": [
    "### Central Limit Theorem (CLT) \n",
    "\n",
    "> Given a dataset with an unknown distribution (it could be uniform, binomial or completely random), the sample means will approximate the normal distribution.\n",
    "\n",
    "For example, suppose that a sample is obtained containing many observations, each observation being randomly generated in a way that does not depend on the values of the other observations, and that the arithmetic mean of the observed values is computed. If this procedure is performed many times, the central limit theorem says that the distribution of the average will be closely approximated by a normal distribution. \n",
    "\n",
    "A simple example of this is that if one flips a coin many times the probability of getting a given number of heads in a series of flips will approach a normal curve, with mean equal to half the total number of flips in each series. In the limit of an infinite number of flips, it will equal a normal curve.\n",
    "\n",
    "The central limit theorem has a number of variants. In its common form, the random variables must be identically distributed, i.e., each random variable has the same probability distribution.\n",
    "\n",
    "In variants, convergence of the mean to the normal distribution also occurs for non-identical distributions or for non-independent observations, given that they comply with certain conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lktsv6UPM_yT"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set matplotlib as inline\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lyv6xSudM_yW"
   },
   "source": [
    "Create population from a non-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIxZEuf6M_yX"
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "population = pd.DataFrame()\n",
    "\n",
    "# Create a column that has 10000 random numbers drawn from a uniform distribution\n",
    "population['numbers'] = np.random.uniform(0,10000,size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDQFi_A4M_yZ"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the data.\n",
    "# This confirms the data is not a normal distribution.\n",
    "p =population['numbers'].hist(bins=100, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olAZYNmKM_yg"
   },
   "source": [
    "View the true mean of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcHOqZieM_yj"
   },
   "outputs": [],
   "source": [
    "# View the mean of the numbers\n",
    "population['numbers'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9qjto6xM_yn"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Explore several parameterizations of the sample mean using the function below. \n",
    "\n",
    "n = sample size  \n",
    "nsamples = number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tR2_O8lPM_yo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample_mean(population, sample_size=100, n_samples=100): \n",
    "    # Create a list\n",
    "    sampled_means = []\n",
    "\n",
    "    # For n_samples\n",
    "    for i in range(0, n_samples):\n",
    "        # Take a random sample from the population, \n",
    "        # take the mean of those rows, append to sampled_means\n",
    "        sampled_means.append(population.sample(sample_size).mean().values[0])\n",
    "    return sampled_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOMDTRVtM_yq"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=10\n",
    "n_samples=10\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bizFCZ-SM_yt"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=10\n",
    "n_samples=100\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49_FiTe3M_yw"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=10\n",
    "n_samples=1000\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9nfHNhZM_yz"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=10\n",
    "n_samples=10000\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGgTCGNWM_y1"
   },
   "source": [
    "Notice how increasing the sample size and the number samples come closer to approximating a true normal distribution of the mean sample statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0rSqKfKM_y2"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=100\n",
    "n_samples=10\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzMoI2i2M_y5"
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of sampled_means. \n",
    "\n",
    "sample_size=100\n",
    "n_samples=100\n",
    "sampled_means = sample_mean(population, sample_size, n_samples)\n",
    "#print(sampled_means)\n",
    "pd.Series(sampled_means).hist(bins=20)\n",
    "plt.suptitle(\"sample_size = \" + str(sample_size) + \" nsamples = \" + str(n_samples));\n",
    "# for s in sampled_means:\n",
    "#     plt.axvline(x=s, linewidth=1, color='g')\n",
    "plt.axvline(x=np.mean(sampled_means), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONJspk7AM_y9"
   },
   "source": [
    "### Confidence interval\n",
    "\n",
    "The confidence level represents the probability that an unknown parameter lies in the stated interval. \n",
    "\n",
    "- The level of confidence can be chosen by the investigator.  \n",
    "- For example, we would like to estimate the confidence interval of the population mean from sample means.\n",
    "- A confidence interval expresses our level of uncertainty, given a level of confidence:\n",
    "    - Given the sample, there is a $95\\%$ likelihood that the range x to y covers the true model accuracy.\n",
    "    - The accuracy of the model was $x \\pm y$ at the $95\\%$ confidence level.\n",
    "\n",
    "#### Confidence Interval Data Requirements\n",
    "\n",
    "The confidence level describes the uncertainty associated with a sampling method. \n",
    "\n",
    "Suppose we used the same sampling method to select different samples and to compute a different interval estimate for each sample. Some interval estimates would include the true population parameter and some would not. \n",
    "\n",
    "A 90% confidence level means that we would expect 90% of the interval estimates to include the population parameter; a 95% confidence level means that 95% of the intervals would include the parameter; and so on.\n",
    "\n",
    "\n",
    "To express a confidence interval, we need the following.\n",
    "\n",
    "- Confidence level\n",
    "- Statistic\n",
    "- Margin of error\n",
    "\n",
    "\n",
    "#### How to Construct a Confidence Interval\n",
    "\n",
    "- Identify a sample statistic. E.g, sample mean, that you will use to estimate a population parameter.\n",
    "\n",
    "- Select a confidence level. The confidence level describes the uncertainty of a sampling method. Often, researchers choose 90%, 95%, or 99% confidence levels. But any percentage can be used.\n",
    "\n",
    "- Use the confidence level to [calculate](https://en.wikipedia.org/wiki/Confidence_interval) or lookup (see table below) the *critical value* $z^*$.\n",
    "\n",
    "|C|z*|\n",
    "|-|-|\n",
    "|99%|2.576|\n",
    "|98%|2.326|\n",
    "|95%|1.96|\n",
    "|90%|1.645|\n",
    "\n",
    "- Find the margin of error. Often, you need to compute the margin of error, based on one of the following equations. Use the first equation if you know the true population standard deviation $\\sigma$, otherwise use the other equation using the standard error $SE$.\n",
    "\n",
    "> Margin of error = Critical value * Standard deviation of statistic\n",
    "> \n",
    "> Margin of error = Critical value * Standard error of statistic\n",
    "> \n",
    "> Standard error:\n",
    "> $SE = \\dfrac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "- Specify the confidence interval. The uncertainty is denoted by the confidence level. The range of the confidence interval is defined by the following equation.\n",
    "\n",
    "Confidence interval = sample statistic $\\pm$ Margin of error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5cP1TfzM_y_"
   },
   "source": [
    "#### Question\n",
    "\n",
    "Confidence interval\n",
    "\n",
    "Determine the confidence interval for the following problem. No python required.\n",
    "\n",
    "We want to estimate the average weight of an adult male in Madison, WI. We draw a random sample of 1,000 men from a population of 1,000,000 men and weigh them. We find that the average man in our sample weighs 180 pounds, and the standard deviation of the sample is 30 pounds. What is the 95% confidence interval?\n",
    "\n",
    "To specify the confidence interval, we work through the steps.\n",
    "\n",
    "- Identify a sample statistic. Since we are trying to estimate the mean weight in the population, we choose the mean weight in our sample (180) as the sample statistic.\n",
    "\n",
    "- Select a confidence level. In this case, the confidence level is defined for us in the problem. We are working with a 95% confidence level.\n",
    "\n",
    "- Find the margin of error. Previously, we described how to compute the margin of error. The key steps are shown below.\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWzpHkFKM_zB"
   },
   "source": [
    "Your work here:\n",
    "    \n",
    "Find standard error. The standard error (SE) of the mean is:\n",
    "\n",
    "\n",
    "\n",
    "Compute margin of error (ME):\n",
    "\n",
    "\n",
    "\n",
    "Specify the confidence interval. The range of the confidence interval is defined by the sample statistic $\\pm$ the margin of error: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngCHl_YQM_zG"
   },
   "source": [
    "#### Optional: calculate critical value\n",
    "\n",
    "The critical value is a factor used to compute the margin of error. \n",
    "\n",
    "To express the critical value as a t score (t*), follow these steps.\n",
    "\n",
    "Compute alpha ($\\alpha$):  \n",
    "$\\alpha = 1 - (\\text{confidence level} / 100) = 0.05$\n",
    "\n",
    "Find the critical probability (p*):  \n",
    "$p* = 1 - \\alpha/2 = 1 - 0.05/2 = 0.975$\n",
    "\n",
    "Find the degrees of freedom (df):   \n",
    "$df = n - 1 = 1000 - 1 = 999$\n",
    "\n",
    "The critical value is the `t-statistic` having $999$ degrees of freedom and a cumulative probability equal to $0.975$. From a t Distribution Calculator or table we find that the critical value is $1.96$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTStbJSgM_zK"
   },
   "source": [
    "#### Question \n",
    "\n",
    "Calculate confidence interval for random distributions \n",
    "\n",
    "For the random `population` data set created above, use the `sampled_means()` function to generate sampled means for `sample_size=10` and `n_samples=10000`.\n",
    "\n",
    "Calculate the margin of error:\n",
    "\n",
    "`scipy.stats.t.interval(alpha, df, loc=0, scale=1)` - Endpoints of the range that contains alpha percent of the distribution\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.t.html\n",
    "\n",
    "and calculute the confidence interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaaktqpSM_zM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGF6AlgYM_zU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# your work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jiUElHSM_zY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IB9pGe4qM_za"
   },
   "outputs": [],
   "source": [
    "mean_confidence_interval(a, confidence=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5zj6sxMM_zf"
   },
   "source": [
    "### Bootstrap  \n",
    "\n",
    "The bootstrap is commonly used to estimate statistics when theory fails. \n",
    "\n",
    "Bootstrap can be used for estimating confidence bounds for convergence in the Monte Carlo integration.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Exponential_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwiVZOmVM_zi"
   },
   "outputs": [],
   "source": [
    "np.random.exponential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dBo1g9vM_zl"
   },
   "source": [
    "For example, what is the 95% confidence interval for the mean of the following generated data set if you didn't know how it was generated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGPu3JWpM_zn"
   },
   "outputs": [],
   "source": [
    "x = np.concatenate([np.random.exponential(size=200), np.random.normal(size=100)])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkK_mmS7M_zt"
   },
   "outputs": [],
   "source": [
    "plt.hist(x, 25, histtype='step');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OifzlXMrM_zz"
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "reps = 100\n",
    "xb = np.random.choice(x, (n, reps))\n",
    "mb = xb.mean(axis=0)\n",
    "mb.sort()\n",
    "\n",
    "np.percentile(mb, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8xn8dsYM_z3"
   },
   "source": [
    "### Experiment:\n",
    "\n",
    "To get a better feel for bootstrap sampling:   \n",
    "    \n",
    "1) Modify `reps` in the cell above an observe how the quantify of bootstrap samples effects confidence intervals.\n",
    "\n",
    "2) Modify the size of the original sample (~3 cells above) an observe the limits of bootstrap with respect to the underlying data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHNzD-x-M_z4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ngCHl_YQM_zG"
   ],
   "name": "04_01_central_limit_theorem_ci_assign.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
