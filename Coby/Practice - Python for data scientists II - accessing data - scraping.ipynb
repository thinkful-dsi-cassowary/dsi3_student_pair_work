{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python (thinkful)","language":"python","name":"thinkful"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Practice - Python for data scientists II - accessing data - scraping.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mb54UjVJenE6","colab_type":"text"},"source":["### Practice - Python for data scientists II - accessing data - scraping\n","\n","Answer all **Questions**\n","\n","In many cases as a data scientist, you’ll have access to data via database, csv format, or an Application Programming Interface (API). However, there are times when the data you want can only be accessed as part of a web page. In this case you will want to use a technique called *web scraping* to get the data from the web page and format it for further analysis.\n","\n","In this notebook, we will go over how to work with the `Requests` and `BeautifulSoup` Python libraries in order to make use of data from web pages. The `Requests` module lets you integrate your Python programs with web services, while the `BeautifulSoup` module is designed to facilitate extracting data from parsed HTML. \n","\n","After an introduction to each library, we'll scrape weather forecasts from the National Weather Service using `Python 3`, the `Requests` and `BeautifulSoup` libraries, and then load the data into a `Pandas` dataframe for further analysis.\n","\n","[Scrapy](https://scrapy.org/) is another web scraping library that also includes a web crawling pipeline. Its a little more difficult to use, but provides greater functionality.\n","\n","Prerequisites:    \n","- Python 3 programming    \n","- Pandas   \n","- Basic HTML, CSS tag knowledge  \n","- Basic understanding of HTTP requests   \n","\n","References:    \n","Beautiful Soup Documentation  \n","- https://www.crummy.com/software/BeautifulSoup/bs4/doc/#   \n","\n","How To Work with Web Data Using Requests and Beautiful Soup with Python 3  \n","- https://www.digitalocean.com/community/tutorials/how-to-work-with-web-data-using-requests-and-beautiful-soup-with-python-3\n","\n","Tutorial: Python Web Scraping Using BeautifulSoup   \n","- https://www.dataquest.io/blog/web-scraping-tutorial-python/   \n","\n","StackOverflow, Difference between BeautifulSoup and Scrapy crawler?         \n","- https://stackoverflow.com/questions/19687421/difference-between-beautifulsoup-and-scrapy-crawler   \n"]},{"cell_type":"markdown","metadata":{"id":"2iC5AFJnenFH","colab_type":"raw"},"source":["# In addition to Python 3, make sure the following libraries are installed\n","# Note: This is a non-executable cell\n","\n","$ pip install pandas   \n","$ pip install requests\n","$ pip install beautifulsoup4"]},{"cell_type":"markdown","metadata":{"id":"PVd9QT_denFI","colab_type":"text"},"source":["### The requests library\n","\n","The `requests` library is the standard library for making HTTP requests in Python. It abstracts the complexities of making HTTP requests behind a relatively simple API.\n","\n","Using the `requests` library will make a `GET` request to a web server, which will retrieve an `HTTP` response with the HTML contents of a given web page. There are several different types of requests we can make using requests, of which GET is just one.  Information on other HTTP methods can be found here:  \n","https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods \n","\n","Using `requests` download a sample web page below.\n","\n","Feel free to try other web pages."]},{"cell_type":"code","metadata":{"id":"s3oxs8NBenFJ","colab_type":"code","colab":{}},"source":["import requests\n","page = requests.get(\"http://jayurbain.com/simplehtml.html\")\n","page"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mB7Cjiq3enFN","colab_type":"text"},"source":["After running the HTTP GET request, we get a `Response` object. This object has a HTTP response `status_code` property, which indicates if the page was downloaded successfully.\n","\n","More on response codes: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n"]},{"cell_type":"code","metadata":{"id":"ZK7eez2fenFP","colab_type":"code","colab":{}},"source":["page.status_code"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIVp2TW-enFW","colab_type":"text"},"source":["A status_code of $200$ means that the page downloaded successfully. A status code starting with a 2 generally indicates success, a code starting with a 4 indicates request (user) error, and a code starting with 5 indicates a server error.\n","\n","Use the response object to print the HTML content of the page using the `content` property:"]},{"cell_type":"code","metadata":{"id":"ikXJ4zRlenFX","colab_type":"code","colab":{}},"source":["page.content"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6SaVBfQTenFb","colab_type":"text"},"source":["### Parsing a web page with BeautifulSoup    \n","\n","Once the page is downloaded, the document needs to be parsed so we can extract data.\n","\n","[`Beautiful Soup`](https://www.crummy.com/software/BeautifulSoup/) creates a parse tree for parsed documents that can be used to extract data from HTML for web scraping.\n","\n","The `BeautifulSoup` library can be used to parse the document downloaded above.\n","\n","Note: `bs4` is the most recent version of BeautifulSoup    \n","https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"]},{"cell_type":"code","metadata":{"id":"1F2j9iEsenFc","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup    \n","soup = BeautifulSoup(page.content, 'html.parser')\n","type(soup)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uoeWx8pKenFg","colab_type":"text"},"source":["We can format and print the HTML content of the page, using the `prettify` method on the `BeautifulSoup` object."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hkbKE_VNenFi","colab_type":"code","colab":{}},"source":["print(soup.prettify())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"utCgAzTbenFm","colab_type":"text"},"source":["Web page documents are represented as a logical tree defined by the Document Object Model (DOM). Each branch of the tree ends in a node, and each node contains objects. Some nodes can be nested with other nodes, others are terminal nodes.\n","\n","References:  \n","- https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model  \n","- https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction  \n","\n","Once parsed, `BeautifulSoup` has methods that allow navigation of the nested tree structure one level at a time, or extraction of specific node elements.\n","\n","For example, we can first select all the elements at the top level of the page using the `children` property of `BeautifulSoup`. \n","\n","Note: `children` returns a list generator, so we need to call the list function."]},{"cell_type":"code","metadata":{"id":"2BAzzM61enFn","colab_type":"code","colab":{}},"source":["[item for item in list(soup.children)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HT-HUHOhenFr","colab_type":"text"},"source":["Top-level children type."]},{"cell_type":"code","metadata":{"id":"ka57I7hPenFs","colab_type":"code","colab":{}},"source":["[type(item) for item in list(soup.children)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51GLcJKGenFv","colab_type":"text"},"source":["Here are some examples showing how to navigate the document data structure:."]},{"cell_type":"code","metadata":{"id":"wH3J0Z__enF2","colab_type":"code","colab":{}},"source":["print('soup.title', soup.title)\n","\n","print('soup.title.name', soup.title.name)\n","\n","print('soup.title.string', soup.title.string)\n","\n","print('soup.title.parent.name', soup.title.parent.name)\n","\n","print('soup.p', soup.p)\n","\n","print(\"soup.find_all('a')\", soup.find_all('a'))\n","\n","print('soup.find(id=\"link3\")', soup.find(id=\"link3\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFZVr7QOenF6","colab_type":"text"},"source":["#### Finding Instances of a Tag\n","\n","Single tags can be extracted from a page by using `Beautiful Soup’s` `find_all` method. This will return all instances of a given tag within a document."]},{"cell_type":"code","metadata":{"id":"Rl0Ao17benF7","colab_type":"code","colab":{}},"source":["soup.find_all('p')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSH71SrYenF-","colab_type":"code","colab":{}},"source":["soup.find_all('a')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5oFkS2lsenGA","colab_type":"text"},"source":["Note: The data above is contained in a list. So we can access individual elements using indexing.\n"]},{"cell_type":"code","metadata":{"id":"kW9MEnvqenGB","colab_type":"code","colab":{}},"source":["soup.find_all('p')[0].get_text()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IS9WSq8penGH","colab_type":"code","colab":{}},"source":["soup.find_all('a')[1].get_text()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5jnez7F-enGJ","colab_type":"text"},"source":["#### Finding Tags by Class or ID\n","\n","HTML elements that refer to CSS selectors like class and ID can be helpful to look at when working with web data using `BeautifulSoup`. Specific classes and IDs can be selected by using the `find_all()` method and passing the class and ID strings as arguments.\n","\n","Find all of the instances of the class *website*. "]},{"cell_type":"code","metadata":{"id":"0bUpyUj5enGK","colab_type":"code","colab":{}},"source":["soup.find_all(class_='website')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvD_ldJqenGN","colab_type":"text"},"source":["You can also search for the class *websigte only within `<a>` tags."]},{"cell_type":"code","metadata":{"id":"bzMyq2zmenGO","colab_type":"code","colab":{}},"source":["soup.find_all('a', class_='website')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ilNbE6KqenGR","colab_type":"text"},"source":["### Practice Exercise\n","\n","\n","#### Web Scraping Example: National Weather Service\n","\n","Load the following page from the National Weather Service:\n","\n","https://forecast.weather.gov/MapClick.php?lat=43.042&lon=-87.9069#.XbXtPEU3ny8\n","\n","<img src=\"national_weather_service_2019-10-27_mke.png\" width=\"600px\"/>\n","    \n","Feel free to try another location, but you usually don't have this nice of weather in Wisconsin this time of year!    "]},{"cell_type":"markdown","metadata":{"id":"prk31eYuenGR","colab_type":"text"},"source":["#### Explore the page structure\n","\n","Prior to scraping a web page, you need to review its structure to identify the elements from which to extract data.\n","\n","The screen shot below uses [Chrome Developer Tools](https://developer.chrome.com/devtools)\n","\n","From the menu (upper-right: 3 vertical dots) select *More Tools -> Developer Tools* then select *Elements* to view HTML elements.\n","\n","<img src=\"chrome_developer_tools_2019-10-27.png\" width=\"600px\"/>\n","\n","*Note: Other browsers have similar tools.*\n","\n","The elements panel will show the HTML tags on the page and let you navigate through nested children. \n","\n","Any element can be selected and inspected. Open and inspect the *seven-day-forecast* div.\n","\n","<img src=\"seven-day-forecast.png\" width=\"600px\"/>\n"]},{"cell_type":"markdown","metadata":{"id":"agqsBaHtenGT","colab_type":"text"},"source":["#### On your own: Scrape the forecast\n","\n","- Download the web page containing the forecast.  \n","page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=43.042&lon=-87.9069#.XbXtPEU3ny8\")   \n","- Create a `BeautifulSoup` class to parse the page.  \n","- Find the `div` with id `seven-day-forecast`, and assign to variable `seven_day`  \n","- Inside seven_day, find each individual forecast item.  \n","- Extract and print the first forecast item.  "]},{"cell_type":"code","metadata":{"id":"qu9O2IX3enGY","colab_type":"code","colab":{}},"source":["# Answer:\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PifHoF6kenGc","colab_type":"text"},"source":["### Additional tutorial information, optional"]},{"cell_type":"markdown","metadata":{"id":"r6JRVI4eenGe","colab_type":"text"},"source":["#### Extracting information \n","\n","We're interested in tonight's forecast. \n","\n","There are 4 pieces of information we can extract:  \n","- The name of the forecast item — in this case, `Tonight`.  \n","- The description of the conditions — this is stored in the `title` property of `img`.  \n","- A short description of the conditions.  \n","- The temperature low.  \n","\n","First, extract the name of the forecast item, the short description, and the temperature."]},{"cell_type":"code","metadata":{"id":"i29z8YDCenGj","colab_type":"code","colab":{}},"source":["period = tonight.find(class_=\"period-name\").get_text()\n","short_desc = tonight.find(class_=\"short-desc\").get_text()\n","temp = tonight.find(class_=\"temp\").get_text()\n","print(period)\n","print(short_desc)\n","print(temp)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dR1bZH4XenGq","colab_type":"text"},"source":["Extract the `title` attribute from the `img` tag. The `BeautifulSoup` object can be treated as a dictionary by passing in the attribute we want as a key.\n"]},{"cell_type":"code","metadata":{"id":"LwHTzFGfenGr","colab_type":"code","colab":{}},"source":["img = tonight.find(\"img\")\n","desc = img['title']\n","print(desc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXh9QRSDenGt","colab_type":"text"},"source":["#### Extracting all the information from the page\n","\n","Select all items with the class `period-name` inside an item with the class `tombstone-container` from seven_day.\n","\n","We can use `list comprehension`s with the `get_text` method on each `BeautifulSoup` object.\n"]},{"cell_type":"code","metadata":{"id":"JGCWtsobenGv","colab_type":"code","colab":{}},"source":["period_tags = seven_day.select(\".tombstone-container .period-name\")\n","periods = [pt.get_text() for pt in period_tags]\n","periods"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_hKZ8PzenGy","colab_type":"text"},"source":["We can apply the same technique to get the other 3 fields."]},{"cell_type":"code","metadata":{"id":"YTGZ1JDIenGz","colab_type":"code","colab":{}},"source":["short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n","print(short_descs)\n","\n","temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n","print(temps)\n","\n","descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n","print(descs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Ssb1lxCenG5","colab_type":"text"},"source":["#### Itegrating Scraped Data in a Pandas Dataframe\n","\n","We can integrate the data into a Pandas DataFrame for analysis. \n"]},{"cell_type":"code","metadata":{"id":"UCm_3b4tenG6","colab_type":"code","colab":{}},"source":["import pandas as pd\n","weather = pd.DataFrame({\n","    \"period\": periods,\n","    \"short_desc\": short_descs,\n","    \"temp\": temps,\n","    \"desc\":descs\n","})\n","weather"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHZtwZ_PenG9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}