{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-dUAbfgpuRb"
   },
   "source": [
    "## Day 23 Lecture 1 Assignment\n",
    "\n",
    "In this assignment, we will explore feature selection and dimensionality reduction techniques. We will use both the FIFA ratings dataset and the Chicago traffic crashes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_data = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/traffic_crashes_chicago.csv')\n",
    "soccer_data = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/fifa_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Name</th>\n      <th>Overall</th>\n      <th>Crossing</th>\n      <th>Finishing</th>\n      <th>HeadingAccuracy</th>\n      <th>ShortPassing</th>\n      <th>Volleys</th>\n      <th>Dribbling</th>\n      <th>Curve</th>\n      <th>...</th>\n      <th>LongShots</th>\n      <th>Aggression</th>\n      <th>Interceptions</th>\n      <th>Positioning</th>\n      <th>Vision</th>\n      <th>Penalties</th>\n      <th>Composure</th>\n      <th>Marking</th>\n      <th>StandingTackle</th>\n      <th>SlidingTackle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>158023</td>\n      <td>L. Messi</td>\n      <td>94</td>\n      <td>84</td>\n      <td>95</td>\n      <td>70</td>\n      <td>90</td>\n      <td>86</td>\n      <td>97</td>\n      <td>93</td>\n      <td>...</td>\n      <td>94</td>\n      <td>48</td>\n      <td>22</td>\n      <td>94</td>\n      <td>94</td>\n      <td>75</td>\n      <td>96</td>\n      <td>33</td>\n      <td>28</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20801</td>\n      <td>Cristiano Ronaldo</td>\n      <td>94</td>\n      <td>84</td>\n      <td>94</td>\n      <td>89</td>\n      <td>81</td>\n      <td>87</td>\n      <td>88</td>\n      <td>81</td>\n      <td>...</td>\n      <td>93</td>\n      <td>63</td>\n      <td>29</td>\n      <td>95</td>\n      <td>82</td>\n      <td>85</td>\n      <td>95</td>\n      <td>28</td>\n      <td>31</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>190871</td>\n      <td>Neymar Jr</td>\n      <td>92</td>\n      <td>79</td>\n      <td>87</td>\n      <td>62</td>\n      <td>84</td>\n      <td>84</td>\n      <td>96</td>\n      <td>88</td>\n      <td>...</td>\n      <td>82</td>\n      <td>56</td>\n      <td>36</td>\n      <td>89</td>\n      <td>87</td>\n      <td>81</td>\n      <td>94</td>\n      <td>27</td>\n      <td>24</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192985</td>\n      <td>K. De Bruyne</td>\n      <td>91</td>\n      <td>93</td>\n      <td>82</td>\n      <td>55</td>\n      <td>92</td>\n      <td>82</td>\n      <td>86</td>\n      <td>85</td>\n      <td>...</td>\n      <td>91</td>\n      <td>76</td>\n      <td>61</td>\n      <td>87</td>\n      <td>94</td>\n      <td>79</td>\n      <td>88</td>\n      <td>68</td>\n      <td>58</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>183277</td>\n      <td>E. Hazard</td>\n      <td>91</td>\n      <td>81</td>\n      <td>84</td>\n      <td>61</td>\n      <td>89</td>\n      <td>80</td>\n      <td>95</td>\n      <td>83</td>\n      <td>...</td>\n      <td>80</td>\n      <td>54</td>\n      <td>41</td>\n      <td>87</td>\n      <td>89</td>\n      <td>86</td>\n      <td>91</td>\n      <td>34</td>\n      <td>27</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>",
      "text/plain": "       ID               Name  Overall  Crossing  Finishing  HeadingAccuracy  \\\n0  158023           L. Messi       94        84         95               70   \n1   20801  Cristiano Ronaldo       94        84         94               89   \n2  190871          Neymar Jr       92        79         87               62   \n3  192985       K. De Bruyne       91        93         82               55   \n4  183277          E. Hazard       91        81         84               61   \n\n   ShortPassing  Volleys  Dribbling  Curve  ...  LongShots  Aggression  \\\n0            90       86         97     93  ...         94          48   \n1            81       87         88     81  ...         93          63   \n2            84       84         96     88  ...         82          56   \n3            92       82         86     85  ...         91          76   \n4            89       80         95     83  ...         80          54   \n\n   Interceptions  Positioning  Vision  Penalties  Composure  Marking  \\\n0             22           94      94         75         96       33   \n1             29           95      82         85         95       28   \n2             36           89      87         81         94       27   \n3             61           87      94         79         88       68   \n4             41           87      89         86         91       34   \n\n   StandingTackle  SlidingTackle  \n0              28             26  \n1              31             23  \n2              24             33  \n3              58             51  \n4              27             22  \n\n[5 rows x 32 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soccer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RD_NO</th>\n      <th>CRASH_DATE</th>\n      <th>POSTED_SPEED_LIMIT</th>\n      <th>TRAFFIC_CONTROL_DEVICE</th>\n      <th>DEVICE_CONDITION</th>\n      <th>WEATHER_CONDITION</th>\n      <th>LIGHTING_CONDITION</th>\n      <th>FIRST_CRASH_TYPE</th>\n      <th>TRAFFICWAY_TYPE</th>\n      <th>LANE_CNT</th>\n      <th>...</th>\n      <th>WORKERS_PRESENT_I</th>\n      <th>NUM_UNITS</th>\n      <th>MOST_SEVERE_INJURY</th>\n      <th>INJURIES_TOTAL</th>\n      <th>INJURIES_FATAL</th>\n      <th>INJURIES_INCAPACITATING</th>\n      <th>INJURIES_NON_INCAPACITATING</th>\n      <th>INJURIES_REPORTED_NOT_EVIDENT</th>\n      <th>INJURIES_NO_INDICATION</th>\n      <th>INJURIES_UNKNOWN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JC334993</td>\n      <td>7/4/2019 22:33</td>\n      <td>45</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>REAR END</td>\n      <td>DIVIDED - W/MEDIAN BARRIER</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JC370822</td>\n      <td>7/30/2019 10:22</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>TURNING</td>\n      <td>DIVIDED - W/MEDIAN (NOT RAISED)</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JC387098</td>\n      <td>8/10/2019 17:00</td>\n      <td>25</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>ONE-WAY</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>JC395195</td>\n      <td>8/16/2019 16:53</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>NOT DIVIDED</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NO INDICATION OF INJURY</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JC396604</td>\n      <td>8/17/2019 16:04</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>PARKING LOT</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NO INDICATION OF INJURY</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>",
      "text/plain": "      RD_NO       CRASH_DATE  POSTED_SPEED_LIMIT TRAFFIC_CONTROL_DEVICE  \\\n0  JC334993   7/4/2019 22:33                  45            NO CONTROLS   \n1  JC370822  7/30/2019 10:22                  30            NO CONTROLS   \n2  JC387098  8/10/2019 17:00                  25            NO CONTROLS   \n3  JC395195  8/16/2019 16:53                  30            NO CONTROLS   \n4  JC396604  8/17/2019 16:04                  30            NO CONTROLS   \n\n  DEVICE_CONDITION WEATHER_CONDITION      LIGHTING_CONDITION  \\\n0      NO CONTROLS             CLEAR  DARKNESS, LIGHTED ROAD   \n1      NO CONTROLS             CLEAR                DAYLIGHT   \n2      NO CONTROLS             CLEAR                DAYLIGHT   \n3      NO CONTROLS             CLEAR                DAYLIGHT   \n4      NO CONTROLS             CLEAR                DAYLIGHT   \n\n       FIRST_CRASH_TYPE                  TRAFFICWAY_TYPE  LANE_CNT  ...  \\\n0              REAR END       DIVIDED - W/MEDIAN BARRIER       NaN  ...   \n1               TURNING  DIVIDED - W/MEDIAN (NOT RAISED)       NaN  ...   \n2  PARKED MOTOR VEHICLE                          ONE-WAY       NaN  ...   \n3  PARKED MOTOR VEHICLE                      NOT DIVIDED       NaN  ...   \n4  PARKED MOTOR VEHICLE                      PARKING LOT       NaN  ...   \n\n  WORKERS_PRESENT_I NUM_UNITS       MOST_SEVERE_INJURY INJURIES_TOTAL  \\\n0               NaN       NaN                      NaN            NaN   \n1               NaN       NaN                      NaN            NaN   \n2               NaN       1.0                      NaN            NaN   \n3               NaN       1.0  NO INDICATION OF INJURY            0.0   \n4               NaN       1.0  NO INDICATION OF INJURY            0.0   \n\n  INJURIES_FATAL INJURIES_INCAPACITATING INJURIES_NON_INCAPACITATING  \\\n0            NaN                     NaN                         NaN   \n1            NaN                     NaN                         NaN   \n2            NaN                     NaN                         NaN   \n3            0.0                     0.0                         0.0   \n4            0.0                     0.0                         0.0   \n\n  INJURIES_REPORTED_NOT_EVIDENT INJURIES_NO_INDICATION INJURIES_UNKNOWN  \n0                           NaN                    NaN              NaN  \n1                           NaN                    NaN              NaN  \n2                           NaN                    NaN              NaN  \n3                           0.0                    1.0              0.0  \n4                           0.0                    1.0              0.0  \n\n[5 rows x 41 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSlVp6FRpuRg"
   },
   "source": [
    "We will begin with the Chicago traffic crashes dataset, focusing on removing columns with significant missing data.\n",
    "\n",
    "Remove all columns with more than 5% missing data from the dataframe. (The *missingness summary* function we wrote a few exercises ago will speed this process up significantly.) Print out the columns that were removed, and the proportion of missing data for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WORKERS_PRESENT_I                99.835205\nDOORING_I                        99.661554\nWORK_ZONE_TYPE                   99.439054\nWORK_ZONE_I                      99.293316\nPHOTOS_TAKEN_I                   98.731833\nSTATEMENTS_TAKEN_I               97.976032\nNOT_RIGHT_OF_WAY_I               95.391656\nINTERSECTION_RELATED_I           77.945704\nHIT_AND_RUN_I                    72.242307\nLANE_CNT                         46.710683\nREPORT_TYPE                       2.301220\nMOST_SEVERE_INJURY                0.579465\nINJURIES_NO_INDICATION            0.577586\nINJURIES_TOTAL                    0.577586\nINJURIES_FATAL                    0.577586\nINJURIES_INCAPACITATING           0.577586\nINJURIES_NON_INCAPACITATING       0.577586\nINJURIES_REPORTED_NOT_EVIDENT     0.577586\nINJURIES_UNKNOWN                  0.577586\nNUM_UNITS                         0.375485\nBEAT_OF_OCCURRENCE                0.001074\nSTREET_DIRECTION                  0.000537\nSTREET_NAME                       0.000268\nTRAFFIC_CONTROL_DEVICE            0.000000\nDEVICE_CONDITION                  0.000000\nPOSTED_SPEED_LIMIT                0.000000\nCRASH_DATE                        0.000000\nWEATHER_CONDITION                 0.000000\nLIGHTING_CONDITION                0.000000\nFIRST_CRASH_TYPE                  0.000000\nTRAFFICWAY_TYPE                   0.000000\nPRIM_CONTRIBUTORY_CAUSE           0.000000\nALIGNMENT                         0.000000\nROADWAY_SURFACE_COND              0.000000\nROAD_DEFECT                       0.000000\nCRASH_TYPE                        0.000000\nDAMAGE                            0.000000\nDATE_POLICE_NOTIFIED              0.000000\nSEC_CONTRIBUTORY_CAUSE            0.000000\nSTREET_NO                         0.000000\nRD_NO                             0.000000\ndtype: float64\n"
    }
   ],
   "source": [
    "# answer goes here\n",
    "\n",
    "# Define a missingness summary that will return a series with column names and what percentage of data in that column is null\n",
    "def missingness_summary(df, print_log, sort):\n",
    "    s = df.isna().sum()*100/len(df)\n",
    "    if sort == 'asc':\n",
    "        s.sort_values(ascending=True, inplace=True)\n",
    "    elif sort == 'desc':\n",
    "        s.sort_values(ascending=False, inplace=True)\n",
    "    if print_log == True:\n",
    "        print(s)\n",
    "    return s\n",
    "\n",
    "# assign the missingness series to a variable\n",
    "missing = missingness_summary(crash_data, True, 'desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WORKERS_PRESENT_I         99.835205\nDOORING_I                 99.661554\nWORK_ZONE_TYPE            99.439054\nWORK_ZONE_I               99.293316\nPHOTOS_TAKEN_I            98.731833\nSTATEMENTS_TAKEN_I        97.976032\nNOT_RIGHT_OF_WAY_I        95.391656\nINTERSECTION_RELATED_I    77.945704\nHIT_AND_RUN_I             72.242307\nLANE_CNT                  46.710683\ndtype: float64\n"
    },
    {
     "data": {
      "text/plain": "Index(['RD_NO', 'CRASH_DATE', 'POSTED_SPEED_LIMIT', 'TRAFFIC_CONTROL_DEVICE',\n       'DEVICE_CONDITION', 'WEATHER_CONDITION', 'LIGHTING_CONDITION',\n       'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'ALIGNMENT',\n       'ROADWAY_SURFACE_COND', 'ROAD_DEFECT', 'REPORT_TYPE', 'CRASH_TYPE',\n       'DAMAGE', 'DATE_POLICE_NOTIFIED', 'PRIM_CONTRIBUTORY_CAUSE',\n       'SEC_CONTRIBUTORY_CAUSE', 'STREET_NO', 'STREET_DIRECTION',\n       'STREET_NAME', 'BEAT_OF_OCCURRENCE', 'NUM_UNITS', 'MOST_SEVERE_INJURY',\n       'INJURIES_TOTAL', 'INJURIES_FATAL', 'INJURIES_INCAPACITATING',\n       'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT',\n       'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN'],\n      dtype='object')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the missing column names with missing percentages > 5\n",
    "missing_too_much = missing.loc[missing > 5]\n",
    "\n",
    "# Print it out\n",
    "print(missing_too_much)\n",
    "\n",
    "# Drop the columns from crash_data\n",
    "crash_data.drop(missing_too_much.index, axis=1, inplace=True)\n",
    "crash_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_h8WYktpuRj"
   },
   "source": [
    "Next, we will shift our focus to the FIFA ratings dataset and explore univariate feature selection techniques. We will treat \"Overall\" as the response and the other ratings as features.\n",
    "\n",
    "Using the correlations between the response and features, identify the 5 features with the greatest univariate correlation to the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Reactions       0.847739\nComposure       0.801749\nShortPassing    0.722720\nBallControl     0.717933\nLongPassing     0.585104\nName: Overall, dtype: float64"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer goes here\n",
    "\n",
    "soccer_corr = soccer_data.corr()\n",
    "correlations = soccer_corr.loc[:,'Overall'].drop('Overall', axis=0)\n",
    "\n",
    "np.abs(correlations).sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iR7m9gANTUxY"
   },
   "source": [
    "Use sklearn's \"SelectKBest\" function to select the top 5 features using two different scoring metrics: f_regression and mutual_info_regression. Print out the top 5 columns that are selected by both. How do they compare to the ones selected by  univariate correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ShortPassing', 'LongPassing', 'BallControl', 'Reactions', 'Composure'], dtype='object')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer goes here\n",
    "\n",
    "Y = soccer_data['Overall']\n",
    "X = soccer_data.drop(['Overall', 'ID', 'Name'], axis=1)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "k = 5\n",
    "kbest_f_reg = SelectKBest(k=k, score_func=f_regression)\n",
    "X_best_features_1 = kbest_f_reg.fit_transform(X, Y)\n",
    "\n",
    "X_best_features_1 = pd.DataFrame(X_best_features_1, columns=X.columns[kbest_f_reg.get_support()]) # Gets column names back into numpy array to make a dataframe for X_best_features\n",
    "\n",
    "X_best_features_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ShortPassing', 'Dribbling', 'BallControl', 'Reactions', 'Composure'], dtype='object')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = soccer_data['Overall']\n",
    "X = soccer_data.drop(['Overall', 'ID', 'Name'], axis=1)\n",
    "\n",
    "k = 5\n",
    "kbest_mi_reg = SelectKBest(k=k, score_func=mutual_info_regression)\n",
    "X_best_features_2 = kbest_mi_reg.fit_transform(X, Y)\n",
    "\n",
    "X_best_features_2 = pd.DataFrame(X_best_features_2, columns=X.columns[kbest_mi_reg.get_support()]) # Gets column names back into numpy array to make a dataframe for X_best_features\n",
    "\n",
    "X_best_features_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Index(['Reactions', 'Composure', 'ShortPassing', 'BallControl', 'LongPassing'], dtype='object')\nIndex(['ShortPassing', 'LongPassing', 'BallControl', 'Reactions', 'Composure'], dtype='object')\nIndex(['ShortPassing', 'Dribbling', 'BallControl', 'Reactions', 'Composure'], dtype='object')\n\nThe first two methods came up with the same features, but in different orders.\nThe last method yielded the 'Dribbling' feature instead of 'LongPassing'\n"
    }
   ],
   "source": [
    "print(np.abs(correlations).sort_values(ascending=False).head(5).index)\n",
    "print(X_best_features_1.columns)\n",
    "print(X_best_features_2.columns)\n",
    "\n",
    "print('\\nThe first two methods came up with the same features, but in different orders.')\n",
    "print('The last method yielded the \\'Dribbling\\' feature instead of \\'LongPassing\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahsyvz1LpuRn"
   },
   "source": [
    "Shifting our focus from feature selection to dimensionality reduction, perform PCA on the ratings provided, excluding \"Overall\". Then, answer the following questions:\n",
    "\n",
    "- What percentage of the total variance is capture by the first component? What about the first two, or first three?\n",
    "- Looking at the components themselves, how would you interpret the first two components in plain English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>principal component 1</th>\n      <th>principal component 2</th>\n      <th>principal component 3</th>\n      <th>principal component 4</th>\n      <th>principal component 5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>149.506331</td>\n      <td>43.713614</td>\n      <td>0.752653</td>\n      <td>-1.024545</td>\n      <td>1.239662</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>132.251163</td>\n      <td>45.030476</td>\n      <td>35.464595</td>\n      <td>-40.513680</td>\n      <td>-1.442205</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>133.728951</td>\n      <td>38.197314</td>\n      <td>-7.738964</td>\n      <td>-6.082813</td>\n      <td>4.220901</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96.639506</td>\n      <td>94.488071</td>\n      <td>8.744320</td>\n      <td>4.223451</td>\n      <td>9.017821</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>129.262864</td>\n      <td>39.657661</td>\n      <td>-5.819084</td>\n      <td>-8.254157</td>\n      <td>11.778411</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   principal component 1  principal component 2  principal component 3  \\\n0             149.506331              43.713614               0.752653   \n1             132.251163              45.030476              35.464595   \n2             133.728951              38.197314              -7.738964   \n3              96.639506              94.488071               8.744320   \n4             129.262864              39.657661              -5.819084   \n\n   principal component 4  principal component 5  \n0              -1.024545               1.239662  \n1             -40.513680              -1.442205  \n2              -6.082813               4.220901  \n3               4.223451               9.017821  \n4              -8.254157              11.778411  "
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer goes here\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Y = soccer_data['Overall']\n",
    "X = soccer_data.drop(['Overall', 'ID', 'Name'], axis=1)\n",
    "\n",
    "k = 5\n",
    "pca = PCA(n_components=k)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(principalComponents, \n",
    "        columns=['principal component {}'.format(n + 1) for n in range(k)])\n",
    "\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Percentage of variance captured by component 1 is 0.39592940781178054\nPercentage of variance captured by component 2 is 0.2633194816048358\nPercentage of variance captured by component 3 is 0.08504495241196014\n"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('Percentage of variance captured by component {} is {}'.format(i + 1,\n",
    "                                                         pca.explained_variance_ratio_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Principal component 1 is a 'fake feature' That represents 39% of the total variance across all features in the dataset.\n",
    "Principal component 1 is a 'fake feature' That represents and additional 26% of the total variance across all features in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONESO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 23 Lecture 1 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}