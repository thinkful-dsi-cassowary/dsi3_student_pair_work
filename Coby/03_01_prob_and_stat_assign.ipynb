{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (thinkful)",
      "language": "python",
      "name": "thinkful"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "03_01_prob_and_stat_assign.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzToGbHoHKlz",
        "colab_type": "text"
      },
      "source": [
        "### Tests for Normality\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeuD0KtsHKl0",
        "colab_type": "text"
      },
      "source": [
        "Various forms of distribution\n",
        "There are various kinds of probability distributions, and each distribution shows the probability of different outcomes for a random experiment.\n",
        "\n",
        "A normal distribution is the most common and widely used distribution in statistics. It is also called a \"bell curve\" and \"Gaussian curve\" \n",
        "\n",
        "A normal distribution occurs commonly in nature.\n",
        "\n",
        "#### What is normality?\n",
        "\n",
        "Normality means that your data follows the normal distribution. Specifically, each value $y_i$ in $Y$ is a ‘realization’ of some normally distributed random variable $N(µ_i, σ_i)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Iy5aeP8HKl2",
        "colab_type": "text"
      },
      "source": [
        "A normal (or Gaussian) distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is\n",
        "\n",
        "$$\n",
        "{\\displaystyle f(x)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x-\\mu }{\\sigma }}\\right)^{2}}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkgONkWdHKl3",
        "colab_type": "text"
      },
      "source": [
        "$$\\int_{-\\infty}^{+\\inf} \\! p(x) \\, \\mathrm{d}x = 1$$\n",
        "\n",
        "$$\n",
        "N(\\mu, \\sigma)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHfPwO0fHKl4",
        "colab_type": "text"
      },
      "source": [
        "Generate and plot a standard norml distribution, i.e.,  $\\mu = 0$ and $\\sigma = 1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1QdzfwHKl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "import matplotlib as mpl\n",
        "\n",
        "mu = 0\n",
        "variance = 1\n",
        "sigma = math.sqrt(variance)\n",
        "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
        "plt.title('Normal Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('p(x)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX5W6N6SHKl8",
        "colab_type": "text"
      },
      "source": [
        "#### Assignment\n",
        "\n",
        "- Generate a random normal distribution with $x_{min} = 0$, $x_{max}=16$, $\\mu = 0$ and $\\sigma = 1$\n",
        "- Use matplotlib to plot your distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-8a4r9IHKl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x_min = 0.0\n",
        "x_max = 16.0\n",
        "\n",
        "mean = 8.0 \n",
        "std = 2.0\n",
        "\n",
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgCdgd2HKmA",
        "colab_type": "text"
      },
      "source": [
        "Here's a more advanced example of plotting the same distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzqCYrwVHKmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "\n",
        "x_min = 0.0\n",
        "x_max = 16.0\n",
        "\n",
        "mean = 8.0 \n",
        "std = 3.0\n",
        "\n",
        "x = np.linspace(x_min, x_max, 100)\n",
        "\n",
        "y = scipy.stats.norm.pdf(x,mean,std)\n",
        "\n",
        "mpl.style.use('default')\n",
        "\n",
        "plt.plot(x,y, color='black')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 1\n",
        "\n",
        "pt1 = mean + std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean - std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#0b559f', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 2\n",
        "\n",
        "pt1 = mean + std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean + 2.0 * std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#2b7bba', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 3\n",
        "\n",
        "pt1 = mean - std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean - 2.0 * std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#2b7bba', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 4\n",
        "\n",
        "pt1 = mean + 2.0 * std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean + 3.0 * std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#539ecd', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 5\n",
        "\n",
        "pt1 = mean - 2.0 * std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean - 3.0 * std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#539ecd', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 6\n",
        "\n",
        "pt1 = mean + 3.0 * std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean + 10.0 *std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#89bedc', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "# fill area 7\n",
        "\n",
        "pt1 = mean - 3.0 * std\n",
        "plt.plot([pt1 ,pt1 ],[0.0,scipy.stats.norm.pdf(pt1 ,mean, std)], color='black')\n",
        "\n",
        "pt2 = mean - 10.0 * std\n",
        "plt.plot([pt2 ,pt2 ],[0.0,scipy.stats.norm.pdf(pt2 ,mean, std)], color='black')\n",
        "\n",
        "ptx = np.linspace(pt1, pt2, 10)\n",
        "pty = scipy.stats.norm.pdf(ptx,mean,std)\n",
        "\n",
        "plt.fill_between(ptx, pty, color='#89bedc', alpha='1.0')\n",
        "\n",
        "#----------------------------------------------------------------------------------------#\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlim(x_min,x_max)\n",
        "plt.ylim(0,0.25)\n",
        "\n",
        "plt.title('Normal Distribution',fontsize=10)\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('p(x)')\n",
        "\n",
        "# plt.savefig(\"normal_distribution_2.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scSJETHhHKmE",
        "colab_type": "text"
      },
      "source": [
        "### Normality Tests in Python\n",
        "\n",
        "In general, if the data Is Gaussian (normal) we can use parametric statistical methods, i.e., a probability density function that takes parameters to generate a distribution. For example $N(\\mu, \\sigma)$ for a normal distribution. So having a normal distribution makes our lives easier. Unfortunately, many important real world distributions are not normal. A significant problem in many statistical analyses is the assumption of normality.\n",
        "    \n",
        "If the data is not normal, then we need to use some form of nonparametric statistical methods to learn a set of parameters to describe the distribution. This usually involves an iterative sampling procedure, where we update our parameter estimamtes for each sample.\n",
        "\n",
        "In terms of modeling, basic methods like linear regression assume a normal distribution. If the distribution is not mormal we must use more advanced models such as topic modeling or neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoA2Z973HKmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate gaussian data\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# summarize\n",
        "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrPyMP4NHKmH",
        "colab_type": "text"
      },
      "source": [
        "### Visual Normality Checks\n",
        "\n",
        "We can create plots of the data to check whether it is Gaussian.\n",
        "\n",
        "These checks are qualitative, so less accurate than the statistical methods we will calculate in the next section. Nevertheless, they are fast and like the statistical tests, must still be interpreted before you can make a call about your data sample.\n",
        "\n",
        "In this section, we will look at two common methods for visually inspecting a dataset to check if it was drawn from a Gaussian distribution.\n",
        "\n",
        "#### Histogram Plot\n",
        "\n",
        "A simple and commonly used plot to quickly check the distribution of a sample of data is the histogram.\n",
        "\n",
        "In the histogram, the data is divided into a pre-specified number of groups called bins. The data is then sorted into each bin and the count of the number of observations in each bin is retained.\n",
        "\n",
        "The plot shows the bins across the x-axis maintaining their ordinal relationship, and the count in each bin on the y-axis.\n",
        "\n",
        "A sample of data has a Gaussian distribution of the histogram plot, showing the familiar bell shape.\n",
        "\n",
        "A histogram can be created using the hist() matplotlib function. By default, the number of bins is automatically estimated from the data sample.\n",
        "\n",
        "A complete example demonstrating the histogram plot on the test problem is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe-YzKgZHKmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# histogram plot\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# histogram plot\n",
        "pyplot.hist(data)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEmkDukuHKmK",
        "colab_type": "text"
      },
      "source": [
        "Running the example creates a histogram plot showing the number of observations in each bin.\n",
        "\n",
        "We can see a Gaussian-like shape to the data, that although is not strongly the familiar bell-shape, is a rough approximation.\n",
        "\n",
        "#### Assignment\n",
        "\n",
        "Does changing the parameters on the historgram improve the normality of the distribution?\n",
        "\n",
        "What about increase the size of the distribution? I.e., rather than using $100$, try $1000$ or $10000$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LckgcfjfHKmL",
        "colab_type": "text"
      },
      "source": [
        "Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaxP74BcHKmM",
        "colab_type": "text"
      },
      "source": [
        "#### Quantile-Quantile Plot\n",
        "\n",
        "Another popular plot for checking the distribution of a data sample is the quantile-quantile plot, Q-Q plot, or QQ plot for short.\n",
        "\n",
        "This plot generates its own sample of the idealized distribution that we are comparing with, in this case the Gaussian distribution. The idealized samples are divided into groups (e.g. 5), called quantiles. Each data point in the sample is paired with a similar member from the idealized distribution at the same cumulative distribution.\n",
        "\n",
        "The resulting points are plotted as a scatter plot with the idealized value on the x-axis and the data sample on the y-axis.\n",
        "\n",
        "A perfect match for the distribution will be shown by a line of dots on a 45-degree angle from the bottom left of the plot to the top right. Often a line is drawn on the plot to help make this expectation clear. Deviations by the dots from the line shows a deviation from the expected distribution.\n",
        "\n",
        "We can develop a QQ plot in Python using the qqplot() statsmodels function. The function takes the data sample and by default assumes we are comparing it to a Gaussian distribution. We can draw the standardized line by setting the ‘line‘ argument to ‘s‘.\n",
        "\n",
        "A complete example of plotting the test dataset as a QQ plot is provided below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kvPiu2bFHKmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# QQ Plot\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from matplotlib import pyplot\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# q-q plot\n",
        "qqplot(data, line='s')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuP-yc4dHKmP",
        "colab_type": "text"
      },
      "source": [
        "#### Assignment\n",
        "\n",
        "Below is code to generate a bimodal distribution.\n",
        "\n",
        "- Generate a QQ-plot with this distribution.\n",
        "- Record your results below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEU_39VHKmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "# Plot a 1D density example\n",
        "N = 100\n",
        "np.random.seed(1)\n",
        "X = np.concatenate((np.random.normal(0, 1, int(0.3 * N)),\n",
        "                    np.random.normal(5, 1, int(0.7 * N))))[:, np.newaxis]\n",
        "\n",
        "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
        "\n",
        "true_dens = (0.3 * norm(0, 1).pdf(X_plot[:, 0])\n",
        "             + 0.7 * norm(5, 1).pdf(X_plot[:, 0]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.fill(X_plot[:, 0], true_dens, fc='black', alpha=0.2,\n",
        "        label='input distribution')\n",
        "\n",
        "for kernel in ['epanechnikov', 'tophat', 'gaussian']:\n",
        "    kde = KernelDensity(kernel=kernel, bandwidth=0.5).fit(X)\n",
        "    log_dens = kde.score_samples(X_plot)\n",
        "    ax.plot(X_plot[:, 0], np.exp(log_dens), '-',\n",
        "            label=\"kernel = '{0}'\".format(kernel))\n",
        "\n",
        "ax.text(6, 0.38, \"N={0} points\".format(N))\n",
        "\n",
        "ax.legend(loc='upper left')\n",
        "data_bi = X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0])\n",
        "ax.plot(data_bi, '+k')\n",
        "\n",
        "ax.set_xlim(-4, 9)\n",
        "ax.set_ylim(-0.02, 0.4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6cZFphRHKmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Your code here:\n",
        "\n",
        "??\n",
        "??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ZagfYwHKmW",
        "colab_type": "text"
      },
      "source": [
        "Your answers here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv0n9AWWHKmX",
        "colab_type": "text"
      },
      "source": [
        "### Testing for Normality using Skewness and Kurtosis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_utmTrFHKmY",
        "colab_type": "text"
      },
      "source": [
        "Several statistical tests are available to test the degree to which your data deviates from normality, and if the deviation is statistically significant.\n",
        "In this article, we’ll look at moment based measures, namely Skewness and Kurtosis, and the statistical tests of significance, namely Omnibus K² and Jarque — Bera, that are based on these measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiTzPwTqHKmZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"446px-Negative_and_positive_skew_diagrams_(English).svg.png\" width=\"400px\"/>\n",
        "\n",
        "Positive and negative skewness (CC BY-SA 3.0)\n",
        "\n",
        "\n",
        "Skewness is defined as the third standardized central moment, of the random variable of the probability distribution.\n",
        "The formula for skewness of the population for random variable $Y$ is shown below:\n",
        "\n",
        "$$\n",
        "\\gamma_1 = E \\left[ \\left(\\dfrac{Y - \\mu}{\\sigma} \\right)^3 \\right]\n",
        "$$\n",
        "\n",
        "Skewness of the normal distribution is zero.\n",
        "While a symmetric distribution will have a zero skewness, a distribution having zero skewness is not necessarily symmetric.\n",
        "\n",
        "Generate an almost random normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89h5Ex6cHKma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import skew \n",
        "import numpy as np  \n",
        "import pylab as p  \n",
        "  \n",
        "x1 = np.linspace( -5, 5, 1000 ) \n",
        "y1 = 1./(np.sqrt(2.*np.pi)) * np.exp( -.5*(x1)**2  )  \n",
        "p.plot(x1, y1) \n",
        "p.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga3PEsi4HKmd",
        "colab_type": "text"
      },
      "source": [
        "Calculate skew:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaIfpNN_HKme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( '\\nSkewness for data : ', skew(y1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9ZgPGYnHKmi",
        "colab_type": "text"
      },
      "source": [
        "Generate a right skew distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k51knKyPHKmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import skewnorm\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "from scipy.stats import skew \n",
        "\n",
        "a = 4\n",
        "mean, var, skew_, kurt = skewnorm.stats(a, moments='mvsk')\n",
        "\n",
        "# Display the probability density function (pdf):\n",
        "\n",
        "x = np.linspace(skewnorm.ppf(0.01, a),\n",
        "                skewnorm.ppf(0.99, a), 100)\n",
        "y2 = skewnorm.pdf(x, a)\n",
        "ax.plot(x, y2,\n",
        "       'r-', alpha=0.6, label='skewnorm pdf')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75SSv7t_HKmr",
        "colab_type": "text"
      },
      "source": [
        "#### Assignment \n",
        "\n",
        "Calculate skewness for the right skew distribution above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVZleRcHKmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APa9tU-2HKmy",
        "colab_type": "text"
      },
      "source": [
        "#### What is ‘Kurtosis’ and how to use it?\n",
        "\n",
        "Kurtosis is a measure of how differently shaped are the tails of a distribution as compared to the tails of the normal distribution. While skewness focuses on the overall shape, Kurtosis focuses on the tail shape.\n",
        "Kurtosis is defined as follows:\n",
        "Kurtosis is the fourth standardized central moment, of the random variable of the probability distribution.\n",
        "The formula for Kurtosis is as follows:\n",
        "\n",
        "$$\n",
        "K = E \\left[ \\left(\\dfrac{Y - \\mu}{\\sigma} \\right)^4 \\right]\n",
        "$$\n",
        "\n",
        "<img src=\"800px-Standard_symmetric_pdfs.png\" width=\"400px\" />\n",
        "\n",
        "\n",
        "image from Wikipedia Commons\n",
        "\n",
        "https://commons.wikimedia.org/wiki/File:Standard_symmetric_pdfs.png\n",
        "\n",
        "Normality tests based on Skewness and Kurtosis\n",
        "While Skewness and Kurtosis quantify the amount of departure from normality, one would want to know if the departure is statistically significant. The following two tests let us do just that.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jG0H-ScTHKmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import kurtosis \n",
        "import numpy as np  \n",
        "import pylab as p  \n",
        "  \n",
        "x1 = np.linspace( -5, 5, 1000 ) \n",
        "y1 = 1./(np.sqrt(2.*np.pi)) * np.exp( -.5*(x1)**2  ) \n",
        "  \n",
        "p.plot(x1, y1, '*') \n",
        "  \n",
        "  \n",
        "print( '\\nKurtosis for normal distribution :', kurtosis(y1)) \n",
        "  \n",
        "print( '\\nKurtosis for normal distribution :',  \n",
        "      kurtosis(y1, fisher = False)) \n",
        "  \n",
        "print( '\\nKurtosis for normal distribution :',  \n",
        "      kurtosis(y1, fisher = True)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9kKskQvHKm4",
        "colab_type": "text"
      },
      "source": [
        "#### More advanced statistical normality tests\n",
        "\n",
        "There are many statistical tests that we can use to quantify whether a sample of data looks as though it was drawn from a Gaussian distribution.\n",
        "\n",
        "*Interpretation of a Test*\n",
        "\n",
        "Before you can apply the statistical tests, you must know how to interpret the results.\n",
        "\n",
        "Each test will return at least two things:\n",
        "\n",
        "- `Statistic`: A quantity calculated by the test that can be interpreted in the context of the test via comparing it to critical values from the distribution of the test statistic.\n",
        "- `p-value`: Used to interpret the test, in this case whether the sample was drawn from a Gaussian distribution.\n",
        "\n",
        "The `statistic` can aid in the interpretation of the result, although it may require a deeper proficiency with statistics and a deeper knowledge of the specific statistical test. Instead, the `p-value` can be used to quickly and accurately interpret the statistic in practical applications.\n",
        "\n",
        "The tests assume that that the sample was drawn from a Gaussian distribution. Technically this is called the null hypothesis, or H0. A threshold level is chosen called alpha, typically 5% (or 0.05), that is used to interpret the p-value.\n",
        "\n",
        "In the SciPy implementation of these tests, you can interpret the `p-value` as follows.\n",
        "\n",
        "- p <= alpha: reject H0, not normal.\n",
        "- p > alpha: fail to reject H0, normal.\n",
        "\n",
        "This means that, in general, we are seeking results with a larger `p-value` to confirm that our sample was likely drawn from a Gaussian distribution.\n",
        "\n",
        "A result above $5\\%$ does not mean that the null hypothesis is true. It means that it is very likely true given available evidence. The `p-value` is not the probability of the data fitting a Gaussian distribution; it can be thought of as a value that helps us interpret the statistical test.\n",
        "\n",
        "#### Shapiro-Wilk Test\n",
        "\n",
        "The Shapiro-Wilk test evaluates a data sample and quantifies how likely it is that the data was drawn from a Gaussian distribution, named for Samuel Shapiro and Martin Wilk.\n",
        "\n",
        "In practice, the Shapiro-Wilk test is believed to be a reliable test of normality, although there is some suggestion that the test may be suitable for smaller samples of data, e.g. thousands of observations or fewer.\n",
        "\n",
        "The `shapiro()` SciPy function will calculate the Shapiro-Wilk on a given dataset. The function returns both the W-statistic calculated by the test and the p-value.\n",
        "\n",
        "The complete example of performing the Shapiro-Wilk test on the dataset is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FndF_wfPHKm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shapiro-Wilk Test\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import shapiro\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# normality test\n",
        "stat, p = shapiro(data)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Sample looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "    print('Sample does not look Gaussian (reject H0)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDrIF5MVHKm9",
        "colab_type": "text"
      },
      "source": [
        "The D’Agostino’s $K^2$ test calculates summary statistics from the data, namely kurtosis and skewness, to determine if the data distribution departs from the normal distribution, named for Ralph D’Agostino.\n",
        "\n",
        "Skew is a quantification of how much a distribution is pushed left or right, a measure of asymmetry in the distribution.\n",
        "\n",
        "Kurtosis quantifies how much of the distribution is in the tail. It is a simple and commonly used statistical test for normality.\n",
        "The D’Agostino’s $K^2$ test is available via the normaltest() SciPy function and returns the test statistic and the `p-value`.\n",
        "\n",
        "The complete example of the D’Agostino’s $K^2$ test on the dataset is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlSy3o7SHKnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# D'Agostino and Pearson's Test\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import normaltest\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# normality test\n",
        "stat, p = normaltest(data)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Sample looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "    print('Sample does not look Gaussian (reject H0)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI-tz1BSHKnE",
        "colab_type": "text"
      },
      "source": [
        "Running the example calculates the statistic and prints the statistic and p-value.\n",
        "\n",
        "The p-value is interpreted against an alpha of 5% and finds that the test dataset does not significantly deviate from normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRu7VQzAHKnF",
        "colab_type": "text"
      },
      "source": [
        "#### Assignment:\n",
        "\n",
        "Evaluate the the Shapiro-Wilk test and the D’Agostino’s $K^2$ on the skewed distribution.\n",
        "\n",
        "Please feel free to adjust the distribution, i.e., skew or kurtosis, to see more significant results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ui4Z88RHKnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxCRQCjRHKnJ",
        "colab_type": "text"
      },
      "source": [
        "#### Anderson-Darling Test\n",
        "\n",
        "The Anderson-Darling Test is a statistical test that can be used to evaluate whether a data sample comes from one of among many known data samples, named for Theodore Anderson and Donald Darling.\n",
        "\n",
        "It can be used to check whether a data sample is normal. The test is a modified version of a more sophisticated nonparametric goodness-of-fit statistical test called the Kolmogorov-Smirnov test.\n",
        "\n",
        "A feature of the Anderson-Darling test is that it returns a list of critical values rather than a single `p-value`. This can provide the basis for a more thorough interpretation of the result.\n",
        "\n",
        "The `anderson()` SciPy function implements the Anderson-Darling test. It takes as parameters the data sample and the name of the distribution to test it against. By default, the test will check against the Gaussian distribution (dist=’norm’).\n",
        "\n",
        "The complete example of calculating the Anderson-Darling test on the sample problem is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS6Rwl9RHKnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Anderson-Darling Test\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import anderson\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(100) + 50\n",
        "# normality test\n",
        "result = anderson(data)\n",
        "print('Statistic: %.3f' % result.statistic)\n",
        "p = 0\n",
        "for i in range(len(result.critical_values)):\n",
        "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
        "    if result.statistic < result.critical_values[i]:\n",
        "        print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
        "    else:\n",
        "        print('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfXS-Z4FHKnR",
        "colab_type": "text"
      },
      "source": [
        "Running the example calculates the statistic on the test data set and prints the critical values.\n",
        "\n",
        "Critical values in a statistical test are a range of pre-defined significance boundaries at which the H0 can be failed to be rejected if the calculated statistic is less than the critical value. Rather than just a single p-value, the test returns a critical value for a range of different commonly used significance levels.\n",
        "\n",
        "We can interpret the results by failing to reject the null hypothesis that the data is normal if the calculated test statistic is less than the critical value at a chosen significance level.\n",
        "\n",
        "We can see that at each significance level, the test has found that the data follows a normal distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLsRbjcXHKnT",
        "colab_type": "text"
      },
      "source": [
        "### What Test Should You Use?\n",
        "\n",
        "We have covered a few normality tests, but this is not all of the tests that exist.\n",
        "\n",
        "So which test do you use?\n",
        "\n",
        "It's generally recommended to use some if not all of them on your data.\n",
        "\n",
        "The question then becomes, how do you interpret the results? What if the tests disagree, which they often will?\n",
        "\n",
        "There are a couple of ways to think about this question.\n",
        "\n",
        "*1. Hard Fail*\n",
        "\n",
        "Your data may not be normal for lots of different reasons. Each test looks at the question of whether a sample was drawn from a Gaussian distribution from a slightly different perspective.\n",
        "\n",
        "A failure of one normality test means that your data is not normal. It's as simple as that.\n",
        "\n",
        "You can either investigate why your data is not normal and perhaps use data preparation techniques to make the data more normal.\n",
        "\n",
        "Or you can start looking into the use of nonparametric statistical methods instead of the parametric methods.\n",
        "\n",
        "*2. Soft Fail*\n",
        "\n",
        "If some of the methods suggest that the sample is Gaussian and some not, then perhaps take this as an indication that your data is `Gaussian-like`.\n",
        "\n",
        "In many situations, you can treat your data as though it is Gaussian and proceed with your chosen parametric statistical methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNnVwmzpHKnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}